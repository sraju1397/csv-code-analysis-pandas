{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T05:34:08.668756Z",
     "start_time": "2024-07-17T05:34:08.664075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "id": "d437309d4d4f9da2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T05:34:08.675092Z",
     "start_time": "2024-07-17T05:34:08.670602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_ticker(df, filename):\n",
    "    # Check if required columns exist\n",
    "    required_columns = ['Ticker', 'Time', 'Date']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Warning: Missing columns in {filename}: {', '.join(missing_columns)}\")\n",
    "        return None\n",
    "\n",
    "    # Filter and process the dataframe\n",
    "    df = df = df[\n",
    "        df['Ticker'].str.match(r'BANKNIFTY-I(\\.NFO)?$', na=False) &\n",
    "        ~df['Ticker'].str.contains('CE', na=False) &\n",
    "        ~df['Ticker'].str.contains('PE', na=False)\n",
    "    ]\n",
    "    \n",
    "    df = df.sort_values(by=['Time', 'Ticker', 'Date'])\n",
    "    \n",
    "    # Drop 'Volume' and 'Open Interest' if they exist\n",
    "    columns_to_drop = ['Volume', 'Open Interest']\n",
    "    existing_columns = [col for col in columns_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=existing_columns)\n",
    "\n",
    "    # Add filename column\n",
    "    df['Filename'] = filename\n",
    "\n",
    "    return df"
   ],
   "id": "a4afa6b0101a4623",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "df204249c1b9d620"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T05:34:22.383181Z",
     "start_time": "2024-07-17T05:34:08.675940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = 'data/Raw GFDL since 2011'\n",
    "output_path = 'output'\n",
    "visited_file = 'output/visited.csv'\n",
    "\n",
    "# Read the visited files CSV\n",
    "file_visited_df = pd.read_csv(visited_file)\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        if filename in file_visited_df['filename'].values:\n",
    "            continue  # Skip this file if it's already been processed\n",
    "        \n",
    "        current_file = os.path.join(dirpath, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(current_file, encoding='utf-8')\n",
    "            df_modified = filter_ticker(df, filename)\n",
    "            \n",
    "            if df_modified is not None and not df_modified.empty:\n",
    "                # Append the modified data to the output CSV\n",
    "                output_file = os.path.join(output_path, 'out.csv')\n",
    "                df_modified.to_csv(output_file, mode='a', header=not os.path.exists(output_file), index=False, encoding='utf-8')\n",
    "                \n",
    "                # Update file_visited_df with the new filename\n",
    "                new_row = pd.DataFrame({'filename': [filename]})\n",
    "                file_visited_df = pd.concat([file_visited_df, new_row], ignore_index=True)\n",
    "                \n",
    "                print(f\"File processed: {filename}\")\n",
    "            else:\n",
    "                print(f\"No data to write after filtering: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {str(e)}\")\n",
    "\n",
    "# Save the updated file_visited_df\n",
    "file_visited_df.to_csv(visited_file, index=False)\n",
    "print(\"All files processed. Updated visited files list saved.\")"
   ],
   "id": "3b76122fe6a958f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processed: GFDLNFO_BACKADJUSTED_03072024.csv\n",
      "File processed: GFDLNFO_BACKADJUSTED_08072024.csv\n",
      "File processed: GFDLNFO_BACKADJUSTED_11072024.csv\n",
      "File processed: GFDLNFO_BACKADJUSTED_05072024.csv\n",
      "File processed: GFDLNFO_BACKADJUSTED_02072024.csv\n",
      "File processed: GFDLNFO_BACKADJUSTED_09072024.csv\n",
      "File processed: GFDLNFO_BACKADJUSTED_04072024.csv\n",
      "File processed: GFDLNFO_BACKADJUSTED_10072024.csv\n",
      "File processed: GFDLNFO_BACKADJUSTED_15072024.csv\n",
      "File processed: GFDLNFO_BACKADJUSTED_01072024.csv\n",
      "File processed: GFDLNFO_BACKADJUSTED_12072024.csv\n",
      "File processed: NSEFO_19082011.csv\n",
      "File processed: NSEFO_12082011.csv\n",
      "File processed: NSEFO_01082011.csv\n",
      "File processed: NSEFO_18082011.csv\n",
      "File processed: NSEFO_26082011.csv\n",
      "File processed: NSEFO_23082011.csv\n",
      "File processed: NSEFO_16082011.csv\n",
      "File processed: NSEFO_04082011.csv\n",
      "File processed: NSEFO_10082011.csv\n",
      "File processed: NSEFO_25082011.csv\n",
      "File processed: NSEFO_09082011.csv\n",
      "File processed: NSEFO_22082011.csv\n",
      "File processed: NSEFO_17082011.csv\n",
      "File processed: NSEFO_03082011.csv\n",
      "File processed: NSEFO_11082011.csv\n",
      "File processed: NSEFO_05082011.csv\n",
      "File processed: NSEFO_24082011.csv\n",
      "File processed: NSEFO_30082011.csv\n",
      "File processed: NSEFO_08082011.csv\n",
      "File processed: NSEFO_29082011.csv\n",
      "All files processed. Updated visited files list saved.\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
